{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18a1814",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # to plot the time series plot\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import math\n",
    "import os\n",
    "\n",
    "from sklearn import metrics # for the evaluation\n",
    "from sklearn.preprocessing import LabelEncoder,MinMaxScaler\n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe860674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to read specific csv files from the output folder and merge them\n",
    "def merge_owid_worldbank_data(country):\n",
    "    \n",
    "    country = country.lower() # just in case, lol\n",
    "    \n",
    "    df_owid = pd.read_csv(f'output/owid_{country}_impute.csv')\n",
    "    df_worldbank = pd.read_csv(f'output/worldbank_{country}_impute.csv')\n",
    "    \n",
    "    df_country = df_owid.merge(df_worldbank, how='left', on='year')\n",
    "    df_country.drop(['iso_code_x', 'country_x'], axis=1, inplace=True)\n",
    "    df_country.rename(columns={'iso_code_y': 'iso_code',\n",
    "                               'country_y': 'country'}, inplace=True)\n",
    "    \n",
    "    # save merged dfs\n",
    "    df_country.to_csv(f'output/merged_{country}.csv', index=False)\n",
    "    \n",
    "    return df_country"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acc898b",
   "metadata": {},
   "source": [
    "##### Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c872a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector = pd.read_csv('dataset\\owid\\ghg-emissions-by-sector.csv') # Additional Sector Dataset\n",
    "df_imputed = pd.read_csv('output\\dataset_worldbank_imputed.csv') # Main Dataset\n",
    "df_china =  merge_owid_worldbank_data('china')\n",
    "df_us =  merge_owid_worldbank_data('us')\n",
    "df_india = merge_owid_worldbank_data('india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3507d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755875ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector[['Transport ']].divide(1.102, axis=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d46041d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector[['Transport ']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5947a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(20,10))\n",
    "df_sector[df_sector.Entity == \"World\"].set_index('Year').plot(figsize=(20,10)).line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba138195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed_china = df_imputed[df_imputed['Country Name'] == \"China\"]\n",
    "df_imputed_china[30:-4].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ae099f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector.columns = df_sector.columns.str.replace(\"(GHG Emissions, CAIT)\", \"\")\n",
    "df_sector.columns = df_sector.columns.str.replace(r\"\\(.*\\)\",\"\")\n",
    "df_sector.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570c57d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector_china = df_sector[df_sector['Code'] == \"CHN\"]\n",
    "df_sector_india = df_sector[df_sector['Code'] == \"IND\"]\n",
    "df_sector_usa = df_sector[df_sector['Code'] == \"USA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15357568",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector_china.shape\n",
    "df_sector_china.iloc[:,2:].plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf4cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector_merged_china = df_imputed_china.merge(df_sector_china, left_on=['Year'], right_on=['Year'],suffixes=('', '_y'))\n",
    "df_sector_merged_china.columns = df_sector_merged_china.columns.str.rstrip()\n",
    "df_sector_merged_china.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c289bd0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Move the Electricity & Heat to last order\n",
    "temp_list = df_sector_merged_china.columns.tolist()\n",
    "temp_list.remove('Electricity & Heat')\n",
    "temp_list.append('Electricity & Heat')\n",
    "df_sector_merged_china = df_sector_merged_china[temp_list]\n",
    "df_sector_merged_china"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac33373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector_merged_china.to_csv('output/sector_merge_china.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42efea36",
   "metadata": {},
   "source": [
    "##### USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24a182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector_usa.iloc[:,:].plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc47a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector_usa.to_csv('output/sector_merge_usa.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f9293",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector_india.to_csv('output/sector_merge_india.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bbc3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84425b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54f44df0",
   "metadata": {},
   "source": [
    "##### machinelearningmastery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3826ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg\n",
    "\n",
    "values = df_sector_merged_china.drop(['Country Name', 'Code', 'Entity','Year'], axis=1)\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "# reframed = series_to_supervised(scaled, 1, 1)\n",
    "reframed = pd.DataFrame(scaled, index=values.index, columns=values.columns)\n",
    "# drop columns we don't want to predict\n",
    "# reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "# print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3253661f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5579a56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_years = 20\n",
    "train = values[:n_train_years, :]\n",
    "test = values[n_train_years:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e981ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cfb337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "reshaped_test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_pred = np.concatenate((reshaped_test_X,yhat), axis=1)\n",
    "inv_pred = scaler.inverse_transform(inv_pred)\n",
    "inv_yhat = inv_pred[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_test = concatenate((test_y, reshaped_test_X), axis=1)\n",
    "inv_test = scaler.inverse_transform(inv_test)\n",
    "inv_y = inv_test[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8685263",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = model.predict(test_X)\n",
    "reshaped_test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_pred = np.concatenate((reshaped_test_X,yhat), axis=1)\n",
    "inv_pred = scaler.inverse_transform(inv_pred)\n",
    "inv_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38feb448",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(inv_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768f1a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scaler.inverse_transform(reframed)).tail(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fec1ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b47b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa475ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56be5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.inverse_transform(concatenate((test_y, test_X), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e525dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f8e2b",
   "metadata": {},
   "source": [
    "##### Future 10 Years Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa1488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future_ten_years():\n",
    "    years_to_predict = list(range(2017, 2027))\n",
    "    n_future_years = len(years_to_predict)\n",
    "    forecast = model.predict(train_X[-n_future_years:])\n",
    "\n",
    "    forecast_copies = np.repeat(forecast, reframed.shape[1], axis=-1)\n",
    "    y_pred_future = scaler.inverse_transform(forecast_copies)[:,0]\n",
    "\n",
    "    forecast_years = []\n",
    "    for year in years_to_predict:\n",
    "        forecast_years.append(year)\n",
    "\n",
    "    df_forecast = pd.DataFrame({\"Year\":np.array(forecast_years), 'Electricity & Heat':y_pred_future})\n",
    "    return df_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2614f259",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_forecast = predict_future_ten_years()\n",
    "df_forecast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76db8175",
   "metadata": {},
   "source": [
    "##### analyticsindiamag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110000da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c37921",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in df_sector_merged_china.select_dtypes('object').columns:\n",
    "   le = LabelEncoder().fit(df_sector_merged_china[i])\n",
    "   df_sector_merged_china[i] = le.transform(df_sector_merged_china[i]) \n",
    "\n",
    "X_scaler = MinMaxScaler()\n",
    "Y_scaler = MinMaxScaler()\n",
    "X_data = X_scaler.fit_transform(df_sector_merged_china[df_sector_merged_china.drop(['Country Name', 'Code', 'Entity','Electricity & Heat', 'Year'], axis=1).columns])\n",
    "Y_data = Y_scaler.fit_transform(df_sector_merged_china[['Electricity & Heat']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19809233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_ts_multi_data_prep(dataset, target, start, end, window, horizon):\n",
    "    X = []\n",
    "    y = []\n",
    "    start = start + window\n",
    "    if end is None:\n",
    "        end = len(dataset) - horizon\n",
    "    for i in range(start, end):\n",
    "        indices = range(i-window, i)\n",
    "        X.append(dataset[indices])\n",
    "        indicey = range(i+1, i+1+horizon)\n",
    "        y.append(target[indicey])\n",
    "    return np.array(X), np.array(y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f872b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_window = 3\n",
    "horizon = 10\n",
    "TRAIN_SPLIT = 17\n",
    "x_train, y_train = custom_ts_multi_data_prep(X_data, Y_data, 0, TRAIN_SPLIT, hist_window, horizon)\n",
    "x_vali, y_vali = custom_ts_multi_data_prep(X_data, Y_data, TRAIN_SPLIT, None, hist_window, horizon) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b74de65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Multiple window of past history\\n')\n",
    "print(x_train[0])\n",
    "print ('\\n Target horizon\\n')\n",
    "print (y_train[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44b9972",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "buffer_size = 150\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(buffer_size).batch(batch_size).repeat()\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_vali, y_vali))\n",
    "val_data = val_data.batch(batch_size).repeat() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6258f202",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(200, return_sequences=True), \n",
    "                            input_shape=x_train.shape[-2:]),\n",
    "    tf.keras.layers.Dense(20, activation='tanh'),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150)),\n",
    "    tf.keras.layers.Dense(20, activation='tanh'),\n",
    "    tf.keras.layers.Dense(20, activation='tanh'),\n",
    "    tf.keras.layers.Dropout(0.25),\n",
    "    tf.keras.layers.Dense(units=horizon),\n",
    "])\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "lstm_model.summary() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ebaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    " model_path = 'Bidirectional_LSTM_Multivariate.h5'\n",
    " early_stopings = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='min')\n",
    " checkpoint =  tf.keras.callbacks.ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True, mode='min', verbose=0)\n",
    " callbacks=[early_stopings,checkpoint] \n",
    "history = lstm_model.fit(train_data,epochs=150,steps_per_epoch=100,validation_data=val_data,validation_steps=50,verbose=1,callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58a8017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector_merged_china = df_sector.merge(df_sector_china, left_on=['Code','Year','Entity'], right_on=['Code','Year','Entity'],suffixes=('', '_y'))\n",
    "df_sector_merged_china.columns = df_sector_merged_china.columns.str.replace(\"_y\", \"\")\n",
    "df_sector_merged_china.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector_merged_india = df_sector.merge(df_sector_india, left_on=['Code','Year','Entity'], right_on=['Code','Year','Entity'],suffixes=('', '_y'))\n",
    "df_sector_merged_india.columns = df_sector_merged_india.columns.str.replace(\"_y\", \"\")\n",
    "df_sector_merged_india.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2476db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sector_merged_usa = df_sector.merge(df_sector_usa, left_on=['Code','Year','Entity'], right_on=['Code','Year','Entity'],suffixes=('', '_y'))\n",
    "df_sector_merged_usa.columns = df_sector_merged_usa.columns.str.replace(\"_y\", \"\")\n",
    "df_sector_merged_usa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4dda50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94d3235",
   "metadata": {},
   "outputs": [],
   "source": [
    "## TO DO\n",
    "# come up with 2 EDA questions + 1 ML question\n",
    "# ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c764a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b72002",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f802925",
   "metadata": {},
   "source": [
    "##### VAR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27bf12",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e0e143810b327d5e077938793196a872c643ae5d9cadd9e9dd1877f5ab05453"
  },
  "kernelspec": {
   "display_name": "Anaconda (base)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
