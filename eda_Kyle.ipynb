{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_china = pd.read_csv('output/merged_china.csv')\n",
    "# df_us = pd.read_csv('output/merged_us.csv')\n",
    "# df_india = pd.read_csv('output/merged_india.csv')\n",
    "\n",
    "# df_raw_owid = pd.read_csv('dataset/owid/owid-co2-data.csv')\n",
    "# df_raw_ghg = pd.read_csv('dataset/owid/ghg-emissions-by-sector.csv')\n",
    "# df_raw_worldbank = pd.read_csv('dataset/worldbank/API.csv')\n",
    "# df_worldbank_meta_country = pd.read_csv('dataset/worldbank/Metadata_Country_API_19_DS2_en_csv_v2_3159902.csv')\n",
    "\n",
    "\n",
    "df_worldbank_imputed = pd.read_csv('output/dataset_worldbank_imputed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall process\n",
    "\n",
    "### EDA\n",
    "EDA for imputed dataset\n",
    "\n",
    "### Preprocessing (again)\n",
    "1. Identify null value\n",
    "2. Overlapping columns (or indicators)\n",
    "2. Imputation \n",
    "    - woid (imputation drop columns)\n",
    "    - worldbank (imputation\n",
    "3. Data transformation\n",
    "\n",
    "reference: [5 stages of data prep for k-means](https://medium.com/@evgen.ryzhkov/5-stages-of-data-preprocessing-for-k-means-clustering-b755426f9932)\n",
    "\n",
    "\n",
    "### K-Means\n",
    "- Euclidean K Means\n",
    "- DBA K Means\n",
    "- Soft DTW K Means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worldbank_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worldbank_imputed.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "### Preprocessing\n",
    "\n",
    "Missing value is being handled by imputation. This preprocessing is to pivot (or transpose) data in column-year format (columns of years), in order to fit into tslearn's kmeans clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperate indicator columns and country year columns\n",
    "df_worldbank_normalized = df_worldbank_imputed.iloc[:, 2:]\n",
    "df_country_and_year = df_worldbank_imputed.iloc[:, :2]\n",
    "  \n",
    "# apply normalization techniques\n",
    "for column in df_worldbank_normalized.columns:\n",
    "    # max scaled normalization\n",
    "    minValue = df_worldbank_normalized.min()\n",
    "    maxValue = df_worldbank_normalized.max()\n",
    "    df_worldbank_normalized=(df_worldbank_normalized-minValue)/(maxValue-minValue)\n",
    "      \n",
    "# merge back country year with normalized data\n",
    "df_worldbank_normalized = pd.concat([df_worldbank_normalized, df_country_and_year], axis=1)\n",
    "\n",
    "# rearrange columns order\n",
    "col = df_worldbank_normalized.columns.tolist()\n",
    "new_col = col[-2:] + col[:-2]\n",
    "df_worldbank_normalized = df_worldbank_normalized[new_col]\n",
    "df_worldbank_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to slice out country from the df\n",
    "# and transpose the data to become column-year format\n",
    "def get_pivot_data_column_year(df, country_name):\n",
    "    \n",
    "    # slice out targeted country and store it inside df_country\n",
    "    df_country = df[df['Country Name'] == f'{country_name}'].copy()\n",
    "    df_country.reset_index(inplace=True, drop=True) \n",
    "\n",
    "    # get ready to transpose\n",
    "    df_country = df_country.iloc[:, 1:] # remove 'Country Name'\n",
    "    df_country.Year = df_country.Year.astype('str') # convert 'year' to string type\n",
    "    df_country = df_country.transpose()\n",
    "    df_country.reset_index(inplace=True) \n",
    "\n",
    "    # reset first row as column\n",
    "    new_header = df_country.iloc[0] # grab the first row for the header\n",
    "    df_country = df_country[1:] # take the data but not header\n",
    "    df_country.columns = new_header # set the header row as the df header\n",
    "    df_country.rename(columns={'Year': 'Indicator Name'}, inplace=True) # rename the column column\n",
    "    df_country.reset_index(inplace=True, drop=True) \n",
    "\n",
    "    # adding new columns\n",
    "    df_country['Country Name'] = f'{country_name}'\n",
    "\n",
    "    # rearrange columns\n",
    "    col = df_country.columns.tolist()\n",
    "    new_col = col[-1:] + col[:-1]\n",
    "    \n",
    "    return df_country[new_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define countries, years and columns\n",
    "countries = df_worldbank_imputed['Country Name'].unique().tolist()\n",
    "years = df_worldbank_imputed['Year'].unique()\n",
    "years = years.tolist()\n",
    "years = [str(year) for year in years]\n",
    "columns = ['Country Name', 'Indicator Name'] + years\n",
    "\n",
    "# loop the entire dataset and transpose all countries\n",
    "df_worldbank_transposed = pd.DataFrame([], columns=columns)\n",
    "for country in countries:\n",
    "    df_temp = get_pivot_data_column_year(df_worldbank_normalized, country) \n",
    "    df_worldbank_transposed = pd.concat([df_worldbank_transposed, df_temp], axis=0, ignore_index=True)\n",
    "    \n",
    "# final result\n",
    "df_worldbank_transposed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_worldbank_transposed['Indicator Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the clustering is not multivariate clustering\n",
    "# so have to choose an variable\n",
    "indicatorName = 'CO2 intensity (kg per kg of oil equivalent energy use)'\n",
    "columnToDrop = ['Indicator Name']\n",
    "\n",
    "df_train = df_worldbank_transposed[df_worldbank_transposed['Indicator Name']== indicatorName]\n",
    "df_train = df_train.drop(columns=columnToDrop)\n",
    "df_train.set_index('Country Name', inplace=True)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert training set into another format for tslearn\n",
    "\n",
    "X_train_co2_intensity = to_time_series_dataset(df_train.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Series K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "\n",
    "# Matplotlib customization\n",
    "%matplotlib inline\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['font.size'] = 14\n",
    "mpl.rcParams['figure.dpi'] = 150.\n",
    "mpl.rcParams[\"figure.figsize\"] = (20,50) #change figure size, (x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of cluster\n",
    "\n",
    "cluster_number = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanKMeans(cluster, seed, X_train):\n",
    "    print(\"Euclidean k-means\")\n",
    "    km = TimeSeriesKMeans(n_clusters=cluster, \n",
    "                          verbose=True, \n",
    "                          random_state=seed, \n",
    "                          max_iter=10)\n",
    "    y_pred = km.fit_predict(X_train)\n",
    "#     clusters = pd.Series(data=y_pred, index=X_train.index)\n",
    "#     clusters\n",
    "\n",
    "    plt.figure()\n",
    "    for yi in range(cluster):\n",
    "        plt.subplot(cluster, 1, yi+1)\n",
    "        for xx in X_train[y_pred == yi]:\n",
    "            plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "        plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.text(0.01, 0.50,'Cluster %d' % (yi + 1),\n",
    "                 transform=plt.gca().transAxes)\n",
    "\n",
    "    print(\"Euclidean k-means Chart\")\n",
    "    plt.show()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBA-k-means\n",
    "def dbaKMeans(cluster, seed, X_train):\n",
    "    print(\"DBA k-means\")\n",
    "    dba_km = TimeSeriesKMeans(n_clusters=cluster,\n",
    "                              n_init=2,\n",
    "                              metric=\"dtw\",\n",
    "                              verbose=True,\n",
    "                              max_iter_barycenter=10,\n",
    "                              random_state=seed)\n",
    "    y_pred = dba_km.fit_predict(X_train)\n",
    "\n",
    "    for yi in range(cluster):\n",
    "        plt.subplot(cluster, 1, yi+1)\n",
    "        for xx in X_train[y_pred == yi]:\n",
    "            plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "        plt.plot(dba_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.text(0.01, 0.50,'Cluster %d' % (yi + 1),\n",
    "                 transform=plt.gca().transAxes)\n",
    "\n",
    "\n",
    "    print(\"DBA k-means Chart\")\n",
    "    plt.show()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft-DTW-k-means\n",
    "def softDTWKmean(cluster, seed, X_train):\n",
    "    print(\"Soft-DTW k-means\")\n",
    "    sdtw_km = TimeSeriesKMeans(n_clusters=cluster,\n",
    "                               metric=\"softdtw\",\n",
    "                               metric_params={\"gamma\": .01},\n",
    "                               verbose=True,\n",
    "                               random_state=seed)\n",
    "    y_pred = sdtw_km.fit_predict(X_train)\n",
    "\n",
    "    for yi in range(cluster):\n",
    "        plt.subplot(cluster, 1, yi+1)\n",
    "        for xx in X_train[y_pred == yi]:\n",
    "            plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "        plt.plot(sdtw_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.text(0.01, 0.50,'Cluster %d' % (yi),\n",
    "                 transform=plt.gca().transAxes)\n",
    "\n",
    "    print(\"Soft-DTW k-means Chart\")\n",
    "    plt.show()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeClusterNames(y_pred, df_index):\n",
    "    clusters = pd.Series(data=y_pred, index=df_index.index)\n",
    "    df_cluster = clusters.to_frame()\n",
    "    df_cluster.columns = ['cluster']\n",
    "    return df_cluster\n",
    "\n",
    "# use this get cluster instead of directly filter it. \n",
    "# Because the graph displayed need to be -1 to get correct cluster name \n",
    "def getSingleCluster(df_cluster, n):\n",
    "    # cluster 1 in the chart represent cluster 0 in the data.\n",
    "    return df_cluster[df_cluster['cluster'] == n-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams[\"figure.figsize\"] = (15,30) #change figure size, (x, y)\n",
    "y_pred_X_euclideanKM_co2_intensity = euclideanKMeans(3, seed, X_train_co2_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_X_euclideanKM_co2_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cluster name\n",
    "cluster_result_euclideanKM_co2_intensity = mergeClusterNames(y_pred_X_euclideanKM_co2_intensity, df_train)\n",
    "cluster_result_euclideanKM_co2_intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_result_euclideanKM_co2_intensity_2 = getSingleCluster(cluster_result_euclideanKM_co2_intensity, 2)\n",
    "cluster_result_euclideanKM_co2_intensity_3 = getSingleCluster(cluster_result_euclideanKM_co2_intensity, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_name_co2_intensity_2 = cluster_result_euclideanKM_co2_intensity_2.index.tolist()\n",
    "\n",
    "df_viz = df_train.reset_index()\n",
    "df_viz = df_viz[df_viz['Country Name'].isin(cluster_name_co2_intensity_2)]\n",
    "df_viz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
