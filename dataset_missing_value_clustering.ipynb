{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Clustering\n",
    "\n",
    "This notebook aims to identify the patterns of missing value and cluster them together.\n",
    "\n",
    "### Motivation\n",
    "\n",
    "When analyzing data, some trends discoverd may be caused by missing value. This notebook aims to address those issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worldbank Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/worldbank/API.csv')\n",
    "meta_country = pd.read_csv('dataset/worldbank/Metadata_Country_API_19_DS2_en_csv_v2_3159902.csv')\n",
    "meta_indicator = pd.read_csv('dataset/worldbank/Metadata_Indicator_API_19_DS2_en_csv_v2_3159902.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data\n",
    "\n",
    "Missing value: fill null value with 0, and fill not null value with 1 (only apply this method on year dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get  columns whose data type is float\n",
    "\n",
    "floatColumns = df.dtypes[df.dtypes == np.float]\n",
    "\n",
    "# list of columns whose data type is float\n",
    "\n",
    "listOfFloatColumnNames = list(floatColumns.index)\n",
    "\n",
    "print(listOfFloatColumnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get  columns whose data type is object\n",
    "\n",
    "objectColumns = df.dtypes[df.dtypes == np.object]\n",
    "\n",
    "# list of columns whose data type is object\n",
    "\n",
    "listOfObjectColumnNames = list(objectColumns.index)\n",
    "\n",
    "print(listOfObjectColumnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique values for country and indicator\n",
    "\n",
    "df[listOfObjectColumnNames].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How the original (not yet preprocessed data) looks like\n",
    "\n",
    "df_years = df[listOfFloatColumnNames]\n",
    "df_years.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan with 0, and fill not nan with 1\n",
    "\n",
    "df_years = df_years.fillna(0)\n",
    "df_years[df_years[listOfFloatColumnNames] != 0] = 1\n",
    "df_years = df_years.astype('int')\n",
    "df_years.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_years.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only indicator name is needed\n",
    "\n",
    "df_indicator = df[listOfObjectColumnNames].iloc[: , 2:3]\n",
    "df_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat df_indicator and df_years back together\n",
    "\n",
    "df_indicatorAndYears = pd.concat([df_indicator, df_years], axis=1)\n",
    "\n",
    "# final preprocessed data\n",
    "\n",
    "df_indicatorAndYears.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by Indicator\n",
    "\n",
    "There are a few ways of checking the pattern of missing value. This section start off with missing value group by indicator, which means all country's data will be grouped (sum) together in each of the 76 indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new copy\n",
    "df_groupBy_indicatorCode = df_indicatorAndYears\n",
    "\n",
    "# Then group by indicator\n",
    "df_groupBy_indicatorCode = df_groupBy_indicatorCode.groupby(['Indicator Name']).sum()\n",
    "df_groupBy_indicatorCode.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop index column first\n",
    "df_check = df_groupBy_indicatorCode.reset_index(drop=True)\n",
    "\n",
    "# check value_counts() for all columns (should get only 0 - 266 )\n",
    "df_check.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple EDA for missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first and second indicator has similar missing value pattern\n",
    "\n",
    "df_temp = (df_groupBy_indicatorCode.iloc[0:5 , :]).transpose()\n",
    "\n",
    "sns.lineplot(data=df_temp, palette=\"tab10\", linewidth=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is another missing value pattern found\n",
    "\n",
    "df_temp = (df_groupBy_indicatorCode.iloc[5:10 , :]).transpose()\n",
    "\n",
    "sns.lineplot(data=df_temp, palette=\"tab10\", linewidth=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more of them\n",
    "\n",
    "df_temp = (df_groupBy_indicatorCode.iloc[10:15 , :]).transpose()\n",
    "\n",
    "sns.lineplot(data=df_temp, palette=\"tab10\", linewidth=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series clustering based on indicator\n",
    "\n",
    "Since there are 76 different indicators and all of them may have different pattern of missing value. This section aim to use time series clustering to group all missing data value pattern into their respective category.\n",
    "\n",
    "The resource of tslearn can be obtained from [tslearn documentation](https://tslearn.readthedocs.io/en/stable/auto_examples/clustering/plot_kmeans.html#sphx-glr-auto-examples-clustering-plot-kmeans-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "\n",
    "# Matplotlib customization\n",
    "%matplotlib inline\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['font.size'] = 14\n",
    "mpl.rcParams['figure.dpi'] = 150.\n",
    "mpl.rcParams[\"figure.figsize\"] = (20,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the data\n",
    "df_groupBy_indicatorCode_normalized = df_groupBy_indicatorCode.copy()\n",
    "  \n",
    "# apply normalization techniques\n",
    "for column in df_groupBy_indicatorCode_normalized.columns:\n",
    "    # max scaled normalization\n",
    "    df_groupBy_indicatorCode_normalized[column] = df_groupBy_indicatorCode_normalized[column]  / 266 \n",
    "      \n",
    "# view normalized data\n",
    "df_groupBy_indicatorCode_normalized.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of cluster\n",
    "\n",
    "cluster_number = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training set (there's no testing set)\n",
    "\n",
    "X_train_indicatorCode = to_time_series_dataset(df_groupBy_indicatorCode_normalized.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanKMeans(cluster, seed, X_train):\n",
    "    print(\"Euclidean k-means\")\n",
    "    km = TimeSeriesKMeans(n_clusters=cluster, \n",
    "                          verbose=True, \n",
    "                          random_state=seed, \n",
    "                          max_iter=10)\n",
    "    y_pred = km.fit_predict(X_train)\n",
    "#     clusters = pd.Series(data=y_pred, index=X_train.index)\n",
    "#     clusters\n",
    "\n",
    "    plt.figure()\n",
    "    for yi in range(cluster):\n",
    "        plt.subplot(cluster, 1, yi+1)\n",
    "        for xx in X_train[y_pred == yi]:\n",
    "            plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "        plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.text(0.01, 0.50,'Cluster %d' % (yi + 1),\n",
    "                 transform=plt.gca().transAxes)\n",
    "\n",
    "    print(\"Euclidean k-means Chart\")\n",
    "    plt.show()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBA-k-means\n",
    "def dbaKMeans(cluster, seed, X_train):\n",
    "    print(\"DBA k-means\")\n",
    "    dba_km = TimeSeriesKMeans(n_clusters=cluster,\n",
    "                              n_init=2,\n",
    "                              metric=\"dtw\",\n",
    "                              verbose=True,\n",
    "                              max_iter_barycenter=10,\n",
    "                              random_state=seed)\n",
    "    y_pred = dba_km.fit_predict(X_train)\n",
    "\n",
    "    for yi in range(cluster):\n",
    "        plt.subplot(cluster, 1, yi+1)\n",
    "        for xx in X_train[y_pred == yi]:\n",
    "            plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "        plt.plot(dba_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.text(0.01, 0.50,'Cluster %d' % (yi + 1),\n",
    "                 transform=plt.gca().transAxes)\n",
    "\n",
    "\n",
    "    print(\"DBA k-means Chart\")\n",
    "    plt.show()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft-DTW-k-means\n",
    "def softDTWKmean(cluster, seed, X_train):\n",
    "    print(\"Soft-DTW k-means\")\n",
    "    sdtw_km = TimeSeriesKMeans(n_clusters=cluster,\n",
    "                               metric=\"softdtw\",\n",
    "                               metric_params={\"gamma\": .01},\n",
    "                               verbose=True,\n",
    "                               random_state=seed)\n",
    "    y_pred = sdtw_km.fit_predict(X_train)\n",
    "\n",
    "    for yi in range(cluster):\n",
    "        plt.subplot(cluster, 1, yi+1)\n",
    "        for xx in X_train[y_pred == yi]:\n",
    "            plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "        plt.plot(sdtw_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "        plt.ylim(0, 1)\n",
    "        plt.text(0.01, 0.50,'Cluster %d' % (yi),\n",
    "                 transform=plt.gca().transAxes)\n",
    "\n",
    "    print(\"Soft-DTW k-means Chart\")\n",
    "    plt.show()\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeClusterNames(y_pred, df_index):\n",
    "    clusters = pd.Series(data=y_pred, index=df_index.index)\n",
    "    df_cluster = clusters.to_frame()\n",
    "    df_cluster.columns = ['cluster']\n",
    "    return df_cluster\n",
    "\n",
    "def getSingleCluster(df_cluster, n):\n",
    "    # cluster 1 in the chart represent cluster 0 in the data.\n",
    "    display(df_cluster[df_cluster['cluster'] == n-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "\n",
    "<span style=\"color:red\">REMINDER:</span> **cluster 1 in the chart represents cluster 0 in data variable**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_Indicator_euclideanKM = euclideanKMeans(cluster_number, seed, X_train_indicatorCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_Indicator_euclideanKM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_Indicator_euclideanKM = mergeClusterNames(y_pred_Indicator_euclideanKM, df_groupBy_indicatorCode)\n",
    "getSingleCluster(cluster_Indicator_euclideanKM, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_Indicator_dbaKM = dbaKMeans(cluster_number, seed, X_train_indicatorCode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_Indicator_dbaKM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_Indicator_dbaKM = mergeClusterNames(y_pred_Indicator_dbaKM, df_groupBy_indicatorCode)\n",
    "getSingleCluster(cluster_Indicator_dbaKM, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getSingleCluster(cluster_Indicator_dbaKM, 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred_Indicator_softDTWKM = softDTWKmean(cluster_number, seed, X_train_indicatorCode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Country column\n",
    "\n",
    "df_country = df[listOfObjectColumnNames].iloc[: , 0:1]\n",
    "df_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat df_country and df_years back together\n",
    "\n",
    "df_countryAndYears = pd.concat([df_country, df_years], axis=1)\n",
    "\n",
    "# final preprocessed data\n",
    "\n",
    "df_countryAndYears.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a new copy\n",
    "df_groupBy_countryName = df_countryAndYears\n",
    "\n",
    "# Then group by country\n",
    "df_groupBy_countryName = df_groupBy_countryName.groupby(['Country Name']).sum()\n",
    "df_groupBy_countryName.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop index column first\n",
    "df_check = df_groupBy_countryName.reset_index(drop=True)\n",
    "\n",
    "# check value_counts() for all columns (should get only 0 - 76 )\n",
    "df_check.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the data\n",
    "df_groupBy_countryName_normalized = df_groupBy_countryName.copy()\n",
    "  \n",
    "# apply normalization techniques\n",
    "for column in df_groupBy_countryName_normalized.columns:\n",
    "    df_groupBy_countryName_normalized[column] = df_groupBy_countryName_normalized[column]  / 76\n",
    "      \n",
    "# view normalized data\n",
    "df_groupBy_countryName_normalized.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series clustering based on country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# country train set\n",
    "\n",
    "X_train_country = to_time_series_dataset(df_groupBy_countryName_normalized.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_country_euclideanKM = euclideanKMeans(5, seed, X_train_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_country_euclideanKM = mergeClusterNames(y_pred_country_euclideanKM, df_groupBy_countryName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getSingleCluster(cluster_country_euclideanKM, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
