{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Value Clustering\n",
    "\n",
    "This notebook aims to identify the patterns of missing value and cluster them together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset/worldbank/API.csv')\n",
    "meta_country = pd.read_csv('dataset/worldbank/Metadata_Country_API_19_DS2_en_csv_v2_3159902.csv')\n",
    "meta_indicator = pd.read_csv('dataset/worldbank/Metadata_Indicator_API_19_DS2_en_csv_v2_3159902.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "Missing value: fill null value with 0, and fill not null value with 1 (only apply this method on year dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get  columns whose data type is float\n",
    "\n",
    "floatColumns = df.dtypes[df.dtypes == np.float]\n",
    "\n",
    "# list of columns whose data type is float\n",
    "\n",
    "listOfFloatColumnNames = list(floatColumns.index)\n",
    "\n",
    "print(listOfFloatColumnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get  columns whose data type is object\n",
    "\n",
    "objectColumns = df.dtypes[df.dtypes == np.object]\n",
    "\n",
    "# list of columns whose data type is object\n",
    "\n",
    "listOfObjectColumnNames = list(objectColumns.index)\n",
    "\n",
    "print(listOfObjectColumnNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of unique country code (will be used as min max normalization)\n",
    "\n",
    "len(df['Country Code'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How the original (not yet preprocessed data) looks like\n",
    "\n",
    "df_years = df[listOfFloatColumnNames]\n",
    "df_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan with 0, and fill not nan with 1\n",
    "\n",
    "df_years = df_years.fillna(0)\n",
    "df_years[df_years[listOfFloatColumnNames] > 0] = 1\n",
    "df_years = df_years.astype('int')\n",
    "df_years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only indicator name is needed\n",
    "\n",
    "df_indicator = df[listOfObjectColumnNames].iloc[: , 2:3]\n",
    "df_indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat df_countryAndIndicator and df_years back together\n",
    "\n",
    "df_indicatorAndYears = pd.concat([df_indicator, df_years], axis=1)\n",
    "\n",
    "# final preprocessed data\n",
    "\n",
    "df_indicatorAndYears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Group by Indicator\n",
    "\n",
    "There are a few ways of checking the pattern of missing value. This section start off with missing value group by indicator, which means all country's data will be grouped (sum) together in each of the 76 indicators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first column of dataframe\n",
    "df_groupBy_indicatorCode = df_indicatorAndYears\n",
    "\n",
    "# Then group by indicator\n",
    "df_groupBy_indicatorCode = df_groupBy_indicatorCode.groupby(['Indicator Name']).sum()\n",
    "df_groupBy_indicatorCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first and second indicator has similar missing value pattern\n",
    "\n",
    "df_temp = (df_groupBy_indicatorCode.iloc[0:5 , :]).transpose()\n",
    "\n",
    "sns.lineplot(data=df_temp, palette=\"tab10\", linewidth=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is another missing value pattern found\n",
    "\n",
    "df_temp = (df_groupBy_indicatorCode.iloc[5:10 , :]).transpose()\n",
    "\n",
    "sns.lineplot(data=df_temp, palette=\"tab10\", linewidth=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more of them\n",
    "\n",
    "df_temp = (df_groupBy_indicatorCode.iloc[10:15 , :]).transpose()\n",
    "\n",
    "sns.lineplot(data=df_temp, palette=\"tab10\", linewidth=2.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series clustering based on indicator\n",
    "\n",
    "Since there are 76 different indicators and all of them may have different pattern of missing value. This section aim to use time series clustering to group all missing data value pattern into their respective category.\n",
    "\n",
    "The resource of tslearn can be obtained from [tslearn documentation](https://tslearn.readthedocs.io/en/stable/auto_examples/clustering/plot_kmeans.html#sphx-glr-auto-examples-clustering-plot-kmeans-py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "from tslearn.utils import to_time_series_dataset\n",
    "\n",
    "# Matplotlib customization\n",
    "%matplotlib inline\n",
    "mpl.rcParams.update(mpl.rcParamsDefault)\n",
    "mpl.rcParams['font.size'] = 14\n",
    "mpl.rcParams['figure.dpi'] = 150.\n",
    "mpl.rcParams[\"figure.figsize\"] = (20,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the data\n",
    "df_max_scaled = df_groupBy_indicatorCode.copy()\n",
    "  \n",
    "# apply normalization techniques\n",
    "for column in df_max_scaled.columns:\n",
    "    df_max_scaled[column] = df_max_scaled[column]  / 266 \n",
    "      \n",
    "# view normalized data\n",
    "df_max_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "\n",
    "X_train = to_time_series_dataset(df_max_scaled.copy())\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set number of cluster\n",
    "\n",
    "cluster = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Euclidean k-means\")\n",
    "km = TimeSeriesKMeans(n_clusters=cluster, \n",
    "                      verbose=True, \n",
    "                      random_state=seed, \n",
    "                      max_iter=10)\n",
    "y_pred = km.fit_predict(X_train)\n",
    "clusters = pd.Series(data=y_pred, index=df_max_scaled.index)\n",
    "clusters\n",
    "\n",
    "plt.figure()\n",
    "for yi in range(cluster):\n",
    "    plt.subplot(cluster, 1, yi+1)\n",
    "    for xx in X_train[y_pred == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "    plt.plot(km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.text(0.01, 0.50,'Cluster %d' % (yi + 1),\n",
    "             transform=plt.gca().transAxes)\n",
    "        \n",
    "print(\"Euclidean k-means Chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DBA-k-means\n",
    "print(\"DBA k-means\")\n",
    "dba_km = TimeSeriesKMeans(n_clusters=cluster,\n",
    "                          n_init=2,\n",
    "                          metric=\"dtw\",\n",
    "                          verbose=True,\n",
    "                          max_iter_barycenter=10,\n",
    "                          random_state=seed)\n",
    "y_pred = dba_km.fit_predict(X_train)\n",
    "\n",
    "for yi in range(cluster):\n",
    "    plt.subplot(cluster, 1, yi+1)\n",
    "    for xx in X_train[y_pred == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "    plt.plot(dba_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.text(0.01, 0.50,'Cluster %d' % (yi + 1),\n",
    "             transform=plt.gca().transAxes)\n",
    "\n",
    "\n",
    "print(\"DBA k-means Chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft-DTW-k-means\n",
    "print(\"Soft-DTW k-means\")\n",
    "sdtw_km = TimeSeriesKMeans(n_clusters=cluster,\n",
    "                           metric=\"softdtw\",\n",
    "                           metric_params={\"gamma\": .01},\n",
    "                           verbose=True,\n",
    "                           random_state=seed)\n",
    "y_pred = sdtw_km.fit_predict(X_train)\n",
    "\n",
    "for yi in range(cluster):\n",
    "    plt.subplot(cluster, 1, yi+1)\n",
    "    for xx in X_train[y_pred == yi]:\n",
    "        plt.plot(xx.ravel(), \"k-\", alpha=.2)\n",
    "    plt.plot(sdtw_km.cluster_centers_[yi].ravel(), \"r-\")\n",
    "    plt.ylim(0, 1)\n",
    "    plt.text(0.01, 0.50,'Cluster %d' % (yi + 1),\n",
    "             transform=plt.gca().transAxes)\n",
    "\n",
    "print(\"Soft-DTW k-means Chart\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Observation\n",
    "1. Pending (work in progress)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
